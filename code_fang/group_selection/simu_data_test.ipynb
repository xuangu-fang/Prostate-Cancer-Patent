{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('pt': conda)"
  },
  "interpreter": {
   "hash": "cb03ba31accc2f25e369d1aa3152af3569125a23627c23321dfacf015e0ff229"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy\n",
    "# import xlrd \n",
    "import sklearn\n",
    "\n",
    "from Gibbs_model import Gibbs_sampling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import baseline_lr,baseline_esnet\n",
    "\n",
    "from scipy.stats import binom \n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import Ridge\n",
    "from tqdm import trange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(500, 50) (500,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# generate simu data\n",
    "N_sample = 500\n",
    "N_feature_t = 6\n",
    "N_feature_f = 44\n",
    "noise_level = 0.1\n",
    "N_feature = N_feature_t + N_feature_f\n",
    "\n",
    "feature_t = np.random.normal(0, 1, size=(N_sample, N_feature_t)) # true feature (should be select)\n",
    "feature_f = np.random.normal(1, 0.5, size=(N_sample, N_feature_f)) # false feaures\n",
    "\n",
    "W_t = np.array([-3, 3, -2, 2, -1, 1])#np.random.normal(0, 1, size=(N_feature_t,1))\n",
    "\n",
    "Y = np.matmul(feature_t, W_t)\n",
    "\n",
    "Y = Y + noise_level*np.random.normal(0, 1, size=Y.shape)\n",
    "\n",
    "X = np.concatenate((feature_t,feature_f),1)\n",
    "print(X.shape,Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0, 1, 6, 7, 8],\n",
       " [2, 3, 9, 10, 11],\n",
       " [4, 5, 12, 13, 14],\n",
       " [15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24],\n",
       " [25, 26, 27, 28, 29],\n",
       " [30, 31, 32, 33, 34],\n",
       " [35, 36, 37, 38, 39],\n",
       " [40, 41, 42, 43, 44],\n",
       " [45, 46, 47, 48, 49]]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# random split the group\n",
    "K = 10 # nunber of group\n",
    "group_ind = []\n",
    "\n",
    "'''\n",
    "for i in range(K):\n",
    "    N_t = N_feature_t//K\n",
    "    N_f = N_feature_f//K\n",
    "    idx_t = [N_t*i +j for j in range(N_t)]\n",
    "    idx_f = [N_feature_t + N_f*i +j for j in range(N_f)]\n",
    "    group_ind.append(idx_t + idx_f)\n",
    "\n",
    "# so in each group, first 10 idx are the ture features\n",
    "'''\n",
    "for i in range(K):\n",
    "    if i < 3:\n",
    "        N_t = 2 #N_feature_t//K\n",
    "        N_f = 3 #N_feature_f//K\n",
    "        idx_t = [N_t*i +j for j in range(N_t)]\n",
    "        idx_f = [N_feature_t + N_f*i +j for j in range(N_f)]\n",
    "        group_ind.append(idx_t + idx_f)\n",
    "    else:\n",
    "        N_f = 5\n",
    "        idx_f = [ N_f*i +j for j in range(N_f)]\n",
    "        group_ind.append(idx_f)\n",
    "\n",
    "group_ind\n",
    "# 0-5 : relevant features\n",
    "# 6-40: unrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(500, 51)\n"
     ]
    }
   ],
   "source": [
    "# re-arrange the features of X based on the group split order\n",
    "X_new = np.concatenate([X[:,group_ind[i]] for i in range(K)],axis=1)\n",
    "\n",
    "# add all-one column at the last \n",
    "bias_col = np.ones(N_sample).reshape((N_sample,1))\n",
    "X_new = np.concatenate((X_new,bias_col),axis=1)\n",
    "\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, Y.squeeze(),test_size=0.2)\n",
    "data_dict = {'X_tr':X_train, 'y_tr':y_train, 'X_test':X_test, 'y_test':y_test}                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init hyper-parameters\n",
    "alpha = 0.5\n",
    "beta = 0.5\n",
    "r0 = 1e-3\n",
    "r1 = 1.0\n",
    "a0 = 1.0\n",
    "b0 = 1.0\n",
    "JITTER = 1e-3\n",
    "\n",
    "INTERVAL = 500\n",
    "VALITA_INTERVAL = 1000\n",
    "BURNING = 5000\n",
    "MAX_NUMBER = 10000\n",
    "\n",
    "hyper_paras = {'INTERVAL':INTERVAL, 'BURNING':BURNING,'MAX_NUMBER':MAX_NUMBER,'VALITA_INTERVAL':VALITA_INTERVAL,\n",
    "'alpha':alpha, 'beta':beta,'r0':r0,'r1':r1,'JITTER':JITTER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init parameters\n",
    "z_array_init = np.random.binomial(size=K, n=1, p= alpha)\n",
    "s_list_init = [np.random.binomial(size=len(item), n=1, p= beta) for item in group_ind]\n",
    "b_init = np.random.normal(loc=0.0, scale=r1,size=None)\n",
    "tau_init = np.random.gamma(shape=alpha, scale=1.0/beta, size=None)\n",
    "W_init = []\n",
    "\n",
    "for i in range(K):\n",
    "    mask1 = 1-z_array_init[i] * s_list_init[i]\n",
    "    mask2 = z_array_init[i] * s_list_init[i]\n",
    "    spike = np.random.normal(loc=0.0, scale=r0,size=len(s_list_init[i]))\n",
    "    slab = np.random.normal(loc=0.0, scale=r1,size=len(s_list_init[i]))\n",
    "    W_group = spike * mask1 + slab * mask2\n",
    "    W_init.append(W_group)\n",
    "\n",
    "init_paras = {'z':z_array_init, 's':s_list_init, 'b':b_init, 'tau':tau_init, 'W':W_init,'a0':a0,'b0':b0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "with lr, rmse is 0.11033\n"
     ]
    }
   ],
   "source": [
    "_ = baseline_lr(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "with elanet, rmse is 2.54218\n"
     ]
    }
   ],
   "source": [
    "_ = baseline_esnet(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 24/10000 [00:00<00:42, 235.92it/s]\n",
      " running test-rmse = 2.89812\n",
      "running train-rmse = 2.81747\n",
      "\n",
      " 10%|█         | 1032/10000 [00:03<00:30, 290.50it/s]\n",
      " running test-rmse = 0.12274\n",
      "running train-rmse = 0.10769\n",
      "\n",
      " 21%|██        | 2053/10000 [00:06<00:25, 307.30it/s]\n",
      " running test-rmse = 0.12072\n",
      "running train-rmse = 0.10534\n",
      "\n",
      " 31%|███       | 3056/10000 [00:10<00:22, 302.25it/s]\n",
      " running test-rmse = 0.11554\n",
      "running train-rmse = 0.10517\n",
      "\n",
      " 41%|████      | 4064/10000 [00:13<00:20, 293.41it/s]\n",
      " running test-rmse = 0.11766\n",
      "running train-rmse = 0.10328\n",
      "\n",
      " 51%|█████     | 5054/10000 [00:17<00:16, 299.95it/s]\n",
      " running test-rmse = 0.12189\n",
      "running train-rmse = 0.10253\n",
      "\n",
      " 60%|██████    | 6049/10000 [00:20<00:12, 304.36it/s]\n",
      " running test-rmse = 0.12184\n",
      "running train-rmse = 0.10567\n",
      "\n",
      " 70%|███████   | 7029/10000 [00:23<00:10, 287.47it/s]\n",
      " running test-rmse = 0.11419\n",
      "running train-rmse = 0.10406\n",
      "\n",
      " 80%|████████  | 8039/10000 [00:27<00:06, 291.40it/s]\n",
      " running test-rmse = 0.11640\n",
      "running train-rmse = 0.10636\n",
      "\n",
      " 91%|█████████ | 9053/10000 [00:30<00:03, 281.32it/s]\n",
      " running test-rmse = 0.11526\n",
      "running train-rmse = 0.10370\n",
      "\n",
      "100%|██████████| 10000/10000 [00:33<00:00, 295.69it/s]\n",
      "\n",
      " final test rmse = 0.10944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Gibbs_sampling(data_dict,init_paras, hyper_paras)\n",
    "model.model_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7372213c9aea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_run_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([1, 1, 0, 0, 0]),\n",
       " array([1, 1, 0, 0, 0]),\n",
       " array([1, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 1, 0]),\n",
       " array([1, 1, 0, 1, 0]),\n",
       " array([0, 1, 1, 1, 1]),\n",
       " array([0, 1, 0, 1, 1]),\n",
       " array([1, 0, 0, 0, 0]),\n",
       " array([1, 0, 1, 0, 1])]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model.s_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "65.70450879667705"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model.tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.052693481985073905"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model.b"
   ]
  }
 ]
}